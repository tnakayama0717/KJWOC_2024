{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b5c8972",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1 Introduction\n",
    "This notebook is for the workshop presented at the AWOC/KJWOC 2024.  \n",
    "This training course covers the basic handling of SGLI products using python in the following sequence.\n",
    "\n",
    "**1. reading data from hdf5 files and converting to geophysical quantities**  \n",
    "SGLI data is stored in integer values for data compression purposes. Therefore, it is necessary to convert from integer values in order to retrieve physical quantities.  \n",
    "\n",
    "**2. Quality control of satellite data using QA flags**  \n",
    "In SGLI data, a flag indicating the quality is set for each pixel. By using these flags appropriately, data of suitable quality for the intended use can be extracted.  \n",
    "\n",
    "**3. Map projection to equirectangular coordinates**  \n",
    "SGLI standard products are distributed on a non-map-projected scene basis. Therefore, a map projection is necessary to determine the difference in geophysical quantities in the area of interest between different dates (satellite orbit paths) or different satellites (MODIS or GOCI2 etc...).   \n",
    "\n",
    "**4. Exercise. Comparison between different sensors using map progections**  \n",
    "Using the map projection technique learnt up to step3, compare SGLI and MODIS Chl-a images of the same day.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9e8e59",
   "metadata": {},
   "source": [
    "# 2 Reading data from HDF5 files\n",
    "## 2.1 Import sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a803009b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'KJWOC_2024' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tnakayama0717/KJWOC_2024/sample_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed04f55f",
   "metadata": {},
   "source": [
    "## 2.2 Import libraries\n",
    "Import the hdf5 and matplotlib libraries required for map projection of SGLI images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c25a8ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db98a6a2",
   "metadata": {},
   "source": [
    "## Target file specification\n",
    "Specify the path to the target file.\n",
    "In this case, select the SST image.  \n",
    "We'll put some sample data in Github, so you can try other sample data in the folder later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84335a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FNAME = 'sample_images/GC1SG1_201809050115H04610_L2SG_SSTDQ_3001.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0283f19",
   "metadata": {},
   "source": [
    "## Check the structure of the hdf5 file\n",
    "The hierarchical structure of HDF5 is similar to that of computers.  \n",
    "However, the names of each element are different, as shown in the table below.   \n",
    "<img src=\"figures_for_markdown/hdfファイル構造概要_en.png\" width=\"50%\">  \n",
    "Check the data structure of the SGLI hdf5 file using python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02db63a-ef72-4b27-88be-b9af15d98b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def PrintAllObjects(name):\n",
    "    print(name)\n",
    "\n",
    "with h5py.File(FNAME,'r') as f:\n",
    "    f.visit(PrintAllObjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fdf6b5-ff81-4ce7-89e5-d3f4591f3378",
   "metadata": {
    "tags": []
   },
   "source": [
    "It can also be found on hdfview ( https://www.hdfgroup.org/download-hdfview/ ), which was introduced yesterday.    \n",
    "<img src=\"figures_for_markdown/hdfファイル構造.png\" width=\"50%\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce5ca0fa-64e3-490c-8cf6-5060c210f1a5",
   "metadata": {},
   "source": [
    "## dataname specification\n",
    "Specify the datename you wish to plot.  \n",
    "The full path, including the hdf5 hierarchy group, must be properly specified.  \n",
    "If you want to show SST, specify ‘/Image_data/SST’.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebddde39-b660-4206-b05c-29043223e04b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "DNAME = '/Image_data/SST'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35781dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d34834ba",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "174dc22a-ecb1-48ce-80fd-22890ff4beb6",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Load the target data immediately and illustrate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68f6e27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(FNAME, 'r') as file:\n",
    "    # Read SST data\n",
    "    Data0 = file[DNAME][:]\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(Data0, cmap='jet')\n",
    "ax.set_title(\"SST DN\")\n",
    "plt.colorbar()\n",
    "#plt.savefig(\"DN.png\", format=\"png\", dpi=2000)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13caf38a-7c2f-4af5-ab63-5ff75c0934af",
   "metadata": {},
   "source": [
    "# Conversion from DN to physical quantity\n",
    "Each physical quantity is stored as an integer value from 0-65535 for data compression purposes (Digital Number = DN).  \n",
    "To convert a DN into a physical quantity, the necessary constants must be read from the attribute associated with each physical quantity and calculated.\n",
    "  \n",
    "## Checking the attribute\n",
    "The attribute set for each dataset can be checked below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d32209b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(FNAME,'r') as file:\n",
    "    dset = file[DNAME].attrs\n",
    "    for k in dset.keys():\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07613ca-77a0-4584-81b6-c994e0cfda6f",
   "metadata": {},
   "source": [
    "Check with hdfview.    \n",
    "<img src=\"figures_for_markdown/attribute.png\" width=\"100%\">  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904c92b3-d58b-4b2d-802d-5a1d1c0913b7",
   "metadata": {},
   "source": [
    "## Conversion from DN to physical quantity\n",
    "For the physical quantity conversion of SGLI data, [**slope**] and [**offset**] must be read and calculated as follows.  \n",
    "**[physical quantity] = [DN]*[slope]+[offset]**  \n",
    "  \n",
    "Also, use [**ErrorDN**] and [**Minimum_valid_DN**], [**Maximum_valid_DN**] to remove invalid pixels before DN conversion.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223d1236-4a2d-4051-8aa6-85d933a1ae50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(FNAME, 'r') as file:\n",
    "    # Read DN\n",
    "    Data0 = file[DNAME][:]\n",
    "    \n",
    "    # Read attributes\n",
    "    Err_DN = file[DNAME].attrs['Error_DN']\n",
    "    Min_DN = file[DNAME].attrs['Minimum_valid_DN']\n",
    "    Max_DN = file[DNAME].attrs['Maximum_valid_DN']\n",
    "    Slope  = file[DNAME].attrs['Slope']\n",
    "    Offset = file[DNAME].attrs['Offset']\n",
    "\n",
    "    # Removal of invalid pixels and physical quantity conversion.\n",
    "    Data1 = Data0.astype(float)\n",
    "    Data1[Data0 == Err_DN] = np.nan\n",
    "    Data1[(Data0 < Min_DN) | (Data0 > Max_DN)] = np.nan\n",
    "    Data1 = Slope * Data1 + Offset\n",
    "    \n",
    "fig, ax = plt.subplots()\n",
    "plt.imshow(Data1, cmap='jet', vmin=15, vmax=35)\n",
    "ax.set_title(\"SST converted from DN\")\n",
    "plt.colorbar(label='SST [deg]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff375f80-0644-44ac-98f8-a42b865cb19b",
   "metadata": {},
   "source": [
    "# Satellite data quality control with QA_flag\n",
    "## QA_flag overview\n",
    "For SGLI data, a QA flag is set for each pixel to indicate its quality.  \n",
    "Screening using the QA flag allows only data of the desired quality to be extracted.  \n",
    "  \n",
    "The QA flags are stored in DN (0-65535) and the flag corresponding to the value of each bit when viewed as a binary number (type uint16) is set.  \n",
    "Example) 16-bit unsigned integer type: 1928 in decimal  \n",
    "<img src=\"figures_for_markdown/bit説明.png\" width=\"70%\">   \n",
    "  \n",
    "Now let's check the contents of the flags corresponding to each bit of QA_flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6146f474-fe50-4afe-8316-f038d40591dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(FNAME,'r') as file:\n",
    "    qa_flag_data_description = file['/Image_data/QA_flag'].attrs['Data_description']\n",
    "    qa_string = qa_flag_data_description.astype(str)\n",
    "    qa_string = \",\".join(qa_string)\n",
    "    qa_string = qa_string.replace(',', '\\n')\n",
    "    print(qa_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8186066-b495-4764-b914-5910e50f8b0d",
   "metadata": {},
   "source": [
    "Information on QA_flag can also be found on the official GCOM-C website.（https://suzaku.eorc.jaxa.jp/GCOM_C/data/update/Algorithm_SST_ja.html）\n",
    "<img src=\"figures_for_markdown/sst_qa_flag.png\" width=\"70%\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba0ce7e-c8f0-4a07-9be2-39f9dc65a055",
   "metadata": {},
   "source": [
    "## Each bit of the QA_flag is illustrated below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd735593-ccbd-4d7f-8e77-501ba39e4d04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(FNAME, 'r') as file:\n",
    "    QA_flag = file['/Image_data/QA_flag'][:]\n",
    "    fig = plt.figure(figsize=(14.0, 4.0))    \n",
    "    for i in range(16):\n",
    "        qa_flag_bit = np.bitwise_and(QA_flag, 2**i, dtype=np.uint16)\n",
    "        ax = fig.add_subplot(2, 8, i+1)\n",
    "        ax.set_title(\"bit\"+ str(i))\n",
    "        im = ax.imshow(qa_flag_bit, vmin=0, vmax=1)\n",
    "        ax.tick_params(labelbottom=False, labelleft=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e59fc-20b0-422c-98fb-c5a963710537",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Applying the QA_flag\n",
    "This time, only pixels where [**good**], [**acceptable**] and [**possibly_cloudy**] stand will be illustrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3e3b60-d84a-4adf-bf35-0575875dadc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with h5py.File(FNAME, 'r') as file:\n",
    "    \n",
    "    # Read QA_flag\n",
    "    QA_flag = file['/Image_data/QA_flag'][:]\n",
    "    possibly_cloudy = np.bitwise_and(QA_flag, 2**12, dtype=np.uint16)\n",
    "    acceptable = np.bitwise_and(QA_flag, 2**13, dtype=np.uint16)\n",
    "    good = np.bitwise_and(QA_flag, 2**14, dtype=np.uint16)\n",
    "\n",
    "    reliable = np.logical_or.reduce([good, acceptable, possibly_cloudy])\n",
    "\n",
    "    # Apply reliability mask\n",
    "    Data1[~reliable] = np.nan\n",
    "\n",
    "    # Plotting with reliability mask\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.imshow(Data1, cmap='jet', vmin=15, vmax=35)\n",
    "    ax.set_title(\"SST with QA flags applied\")\n",
    "    plt.colorbar(label='SST [deg]')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da95c5d-456e-4a1a-a879-09efeb8395b8",
   "metadata": {},
   "source": [
    "# Conversion to latitude and longitude coordinates\n",
    "Polar-orbiting satellite SGLI images are provided just as scanned by the satellite (Scene).  \n",
    "In order to map project them to latitude and longitude coordinates, a 2D interpolation must be performed to transform the coordinates.  \n",
    "<img src=\"figures_for_markdown/SGLI_スキャン概念図.png\" width=\"80%\"> \n",
    "\n",
    "## Loading latitude and longitude information\n",
    "The SGLI latitude and longitude information is stored in 10-pix thinning (Resampling_interval), so it must first be interpolated to the same resolution as the physical quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfe1213b-616c-49f2-a5bc-23e93f4b7700",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chunk_size = 1000  # Chunk size for rows\n",
    "\n",
    "with h5py.File(FNAME, 'r') as file:\n",
    "    Data0_shape = file[DNAME].shape\n",
    "    Lat_shape = file['/Geometry_data/Latitude'].shape\n",
    "    Lon_shape = file['/Geometry_data/Longitude'].shape\n",
    "    \n",
    "    Lat_r = float(file['/Geometry_data/Latitude'].attrs['Resampling_interval'])\n",
    "    Lon_r = float(file['/Geometry_data/Longitude'].attrs['Resampling_interval']) \n",
    "\n",
    "    # Create meshgrid for the original Latitude and Longitude data\n",
    "    X, Y = np.meshgrid(np.arange(0, Lat_r * Lat_shape[1], Lat_r),\n",
    "                       np.arange(0, Lat_r * Lat_shape[0], Lat_r))\n",
    "\n",
    "    # Prepare output arrays for interpolated Latitude and Longitude\n",
    "    f_lat = np.empty(Data0_shape, dtype=np.float32)\n",
    "    f_lon = np.empty(Data0_shape, dtype=np.float32)\n",
    "\n",
    "    # Process data in chunks\n",
    "    for start_row in range(0, Data0_shape[0], chunk_size):\n",
    "        end_row = min(start_row + chunk_size, Data0_shape[0])\n",
    "\n",
    "        # Create query meshgrid corresponding to the Data0 shape for this chunk\n",
    "        Xq, Yq = np.meshgrid(np.arange(0, Data0_shape[1]),\n",
    "                             np.arange(start_row, end_row))\n",
    "        \n",
    "        # Convert Latitude and Longitude indices to integers\n",
    "        start_row_geo = int(start_row / 10)\n",
    "        end_row_geo = int(end_row / 10) + 1\n",
    "\n",
    "        # Flatten the X, Y for interpolation\n",
    "        points = np.column_stack([X[start_row_geo:end_row_geo, :].flatten(), Y[start_row_geo:end_row_geo, :].flatten()])\n",
    "\n",
    "        # Slice using Latitude and Longitude indices\n",
    "        lat_chunk = file['/Geometry_data/Latitude'][start_row_geo:end_row_geo, :].flatten()\n",
    "        lon_chunk = file['/Geometry_data/Longitude'][start_row_geo:end_row_geo, :].flatten()\n",
    "\n",
    "        # Interpolate Latitude and Longitude for the current chunk\n",
    "        f_lat[start_row:end_row, :] = griddata(points, lat_chunk, (Xq, Yq), method='linear')\n",
    "        f_lon[start_row:end_row, :] = griddata(points, lon_chunk, (Xq, Yq), method='linear')\n",
    "\n",
    "    LLroi = {'Lat': f_lat, 'Lon': f_lon}\n",
    "\n",
    "    # Plotting\n",
    "    fig = plt.figure()\n",
    "    plt.subplots_adjust(wspace=0.6, hspace=0.6)\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.set_title(\"Latitude\")\n",
    "    im1 = ax1.imshow(LLroi['Lat'], vmin=30, vmax=45, cmap='jet')\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    divider = make_axes_locatable(ax1)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(im1, cax=cax)\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.set_title(\"Longitude\")\n",
    "    im2 = ax2.imshow(LLroi['Lon'], vmin=130, vmax=150, cmap='jet')\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    divider = make_axes_locatable(ax2)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(im2, cax=cax)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a84b60a-310d-4cc7-a4bb-451b37f6bc31",
   "metadata": {},
   "source": [
    "## Cut out target area\n",
    "Spatial interpolation of 250 m resolution images is a long processing time and a heavy burden on memory.  \n",
    "In particular, Google Colab takes a relatively long time to process and has an upper limit on the memory used, so this time a specific area is cut out and projected onto the map.  \n",
    "  \n",
    "In this case, the target area is Tokyo Bay.(red box)  \n",
    "<img src=\"figures_for_markdown/SST_without_QC_tokyo_bay.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3ac80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define latitude and longitude limits\n",
    "lat_min = 35.0\n",
    "lat_max = 35.8\n",
    "lon_min = 139.5\n",
    "lon_max = 140.2\n",
    "\n",
    "# Identify target area within specified latitude and longitude range\n",
    "tgt_area = (LLroi['Lat'] > lat_min) & (LLroi['Lat'] < lat_max) & (LLroi['Lon'] > lon_min) & (LLroi['Lon'] < lon_max)\n",
    "\n",
    "# Find the row indices where any value in the row satisfies the condition\n",
    "tgt_pix = np.where(np.sum(tgt_area, axis=1) > 0)[0]\n",
    "\n",
    "# Find the column indices where any value in the column satisfies the condition\n",
    "tgt_lin = np.where(np.sum(tgt_area, axis=0) > 0)[0]\n",
    "\n",
    "# Get the min and max indices for rows and columns\n",
    "pix_min = tgt_pix[0]\n",
    "pix_max = tgt_pix[-1]\n",
    "lin_min = tgt_lin[0]\n",
    "lin_max = tgt_lin[-1]\n",
    "\n",
    "# Extract the sub-region of lat and lon within the target area\n",
    "tgt_lat = LLroi['Lat'][pix_min:pix_max+1, lin_min:lin_max+1]\n",
    "tgt_lon = LLroi['Lon'][pix_min:pix_max+1, lin_min:lin_max+1]\n",
    "\n",
    "# Assuming data0 is a NumPy array, extract the corresponding data\n",
    "tgt_data0 = Data1[pix_min:pix_max+1, lin_min:lin_max+1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cd6030",
   "metadata": {},
   "source": [
    "## Set resolution after map projection\n",
    "Create a grid after map projection. Here, try map projection at **0.0025 [deg]** intervals.  \n",
    "0.0025 deg is roughly 250 m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72bcd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddeg = 0.0025\n",
    "\n",
    "# Create latitude and longitude grids with specified resolution ddeg\n",
    "latg = np.arange(lat_max, lat_min - ddeg, -ddeg)\n",
    "long = np.arange(lon_min, lon_max + ddeg, ddeg)\n",
    "\n",
    "# Generate a grid for map projection\n",
    "llg_lat, llg_lon = np.meshgrid(latg, long, indexing='ij')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60868854",
   "metadata": {},
   "source": [
    "## Projection to latitude and longitude coordinates\n",
    "Map projection using python functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b075e6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolation using griddata\n",
    "points = np.column_stack((tgt_lat.flatten(), tgt_lon.flatten()))\n",
    "values = tgt_data0.flatten()\n",
    "\n",
    "# Interpolate data over the new grid\n",
    "Data2 = griddata(points, values, (llg_lat, llg_lon), method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bd70a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig = plt.figure()\n",
    "plt.subplots_adjust(wspace=0.6, hspace=0.6)\n",
    "\n",
    "# First subplot: original data\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.set_title(\"Scene Data\")\n",
    "ax1.set_xlabel('pixel')\n",
    "ax1.set_ylabel('line')\n",
    "im1 = ax1.imshow(tgt_data0, vmin=24, vmax=31, cmap='jet')\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "plt.colorbar(im1, cax=cax)\n",
    "\n",
    "# Second subplot: interpolated data in map projection\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.set_title(\"Map Projection\")\n",
    "ax2.set_xlabel('Longitude [deg]')\n",
    "ax2.set_ylabel('Latitude [deg]')\n",
    "im2 = ax2.pcolormesh(long, latg, Data2, vmin=24, vmax=31, cmap='jet')\n",
    "ax2.set_aspect('equal', adjustable='box')\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "plt.colorbar(im2, cax=cax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6e17f0",
   "metadata": {},
   "source": [
    "# Exercise. Comparison between different sensors using map projections\n",
    "Map-project the Chl-a images of the different sensors, SGLI and MODIS respectively, to see the differences.  \n",
    "The different orbits and fields of view of MODIS and SGLI make it difficult to compare their spatial distribution using scene images.   \n",
    "Therefore, map projection onto equirectangular coordinates should facilitate comparison of spatial distributions and create spatial deviations and scatter plots.\n",
    "\n",
    "\n",
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106acd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import griddata\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f39b06",
   "metadata": {},
   "source": [
    "## SGLI FILE\n",
    "Let's start with a map projection of the SGLI Chl-a image for review.\n",
    "### Check the structure of the hdf5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feaadac",
   "metadata": {},
   "outputs": [],
   "source": [
    "SGLI_FNAME = \"sample_images/GC1SG1_201910130153P05810_L2SG_IWPRK_3000.h5\"\n",
    "def PrintAllObjects(name):\n",
    "    print(name)\n",
    "\n",
    "with h5py.File(SGLI_FNAME,'r') as f:\n",
    "    f.visit(PrintAllObjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8da1e2d",
   "metadata": {},
   "source": [
    "### Dataname specification and checking the attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4323437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNAME = '/Image_data/CHLA'\n",
    "\n",
    "with h5py.File(SGLI_FNAME,'r') as file:\n",
    "    dset = file[DNAME].attrs\n",
    "    for k in dset.keys():\n",
    "        print(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0646c7",
   "metadata": {},
   "source": [
    "### conversion from DN to physical quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1ca619",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(SGLI_FNAME, 'r') as file:\n",
    "    # Read DN\n",
    "    SGLI_Data0 = file[DNAME][:]\n",
    "    \n",
    "    # Read attributes\n",
    "    Err_DN = file[DNAME].attrs['Error_DN']\n",
    "    Min_DN = file[DNAME].attrs['Minimum_valid_DN']\n",
    "    Max_DN = file[DNAME].attrs['Maximum_valid_DN']\n",
    "    Slope  = file[DNAME].attrs['Slope']\n",
    "    Offset = file[DNAME].attrs['Offset']\n",
    "\n",
    "    # Removal of invalid pixels and physical quantity conversion.\n",
    "    SGLI_Data1 = SGLI_Data0.astype(float)\n",
    "    SGLI_Data1[SGLI_Data1 == Err_DN] = np.nan\n",
    "    SGLI_Data1[(SGLI_Data1 <= Min_DN) | (SGLI_Data1 >= Max_DN)] = np.nan\n",
    "    SGLI_Data1 = Slope * SGLI_Data1 + Offset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15edf24",
   "metadata": {},
   "source": [
    "### Applying the QA_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b17dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(SGLI_FNAME,'r') as file:\n",
    "    qa_flag_data_description = file['/Image_data/QA_flag'].attrs['Data_description']\n",
    "    qa_string = qa_flag_data_description.astype(str)\n",
    "    qa_string = \",\".join(qa_string)\n",
    "    qa_string = qa_string.replace(',', '\\n')\n",
    "    print(qa_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e18f926",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(SGLI_FNAME, 'r') as file:\n",
    "    \n",
    "    # Read QA_flag\n",
    "    QA_flag = file['/Image_data/QA_flag']\n",
    "\n",
    "    bit00 = np.bitwise_and(QA_flag, 2**1, dtype=np.uint16)\n",
    "    bit01 = np.bitwise_and(QA_flag, 2**2, dtype=np.uint16)\n",
    "    bit02 = np.bitwise_and(QA_flag, 2**3, dtype=np.uint16)\n",
    "    bit03 = np.bitwise_and(QA_flag, 2**4, dtype=np.uint16)\n",
    "    bit04 = np.bitwise_and(QA_flag, 2**5, dtype=np.uint16)\n",
    "    bit05 = np.bitwise_and(QA_flag, 2**6, dtype=np.uint16)\n",
    "    bit06 = np.bitwise_and(QA_flag, 2**7, dtype=np.uint16)\n",
    "    bit07 = np.bitwise_and(QA_flag, 2**8, dtype=np.uint16)\n",
    "    bit08 = np.bitwise_and(QA_flag, 2**9, dtype=np.uint16)\n",
    "    bit09 = np.bitwise_and(QA_flag, 2**10, dtype=np.uint16)\n",
    "    bit10 = np.bitwise_and(QA_flag, 2**11, dtype=np.uint16)\n",
    "    bit11 = np.bitwise_and(QA_flag, 2**12, dtype=np.uint16)\n",
    "    bit12 = np.bitwise_and(QA_flag, 2**13, dtype=np.uint16)\n",
    "    bit13 = np.bitwise_and(QA_flag, 2**14, dtype=np.uint16)\n",
    "    bit14 = np.bitwise_and(QA_flag, 2**15, dtype=np.uint16)\n",
    "    bit15 = np.bitwise_and(QA_flag, 2**16, dtype=np.uint16)\n",
    "    \n",
    "    #unreliable = np.logical_or.reduce([bit00,bit01,bit02,bit03,bit06,bit08,bit09,bit10])\n",
    "    unreliable = np.logical_or.reduce([bit00,bit01])\n",
    "    # Apply reliability mask\n",
    "    SGLI_Data1[unreliable] = np.nan\n",
    "\n",
    "    # Plotting with reliability mask\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.imshow(SGLI_Data1, cmap='jet', vmin=0, vmax=5)\n",
    "    ax.set_title(\"SST with QA flags applied\")\n",
    "    plt.colorbar(label='CHLA [g/m^3]')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1e3c70",
   "metadata": {},
   "source": [
    "### Loading latitude and longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3c790c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 500  # Chunk size for rows\n",
    "\n",
    "with h5py.File(SGLI_FNAME, 'r') as file:\n",
    "    Data0_shape = file[DNAME].shape\n",
    "    Lat_shape = file['/Geometry_data/Latitude'].shape\n",
    "    Lon_shape = file['/Geometry_data/Longitude'].shape\n",
    "    \n",
    "    Lat_r = float(file['/Geometry_data/Latitude'].attrs['Resampling_interval'])\n",
    "    Lon_r = float(file['/Geometry_data/Longitude'].attrs['Resampling_interval']) \n",
    "\n",
    "    # Create meshgrid for the original Latitude and Longitude data\n",
    "    X, Y = np.meshgrid(np.arange(0, Lat_r * Lat_shape[1], Lat_r),\n",
    "                       np.arange(0, Lat_r * Lat_shape[0], Lat_r))\n",
    "\n",
    "    # Prepare output arrays for interpolated Latitude and Longitude\n",
    "    f_lat = np.empty(Data0_shape, dtype=np.float32)\n",
    "    f_lon = np.empty(Data0_shape, dtype=np.float32)\n",
    "\n",
    "    # Process data in chunks\n",
    "    for start_row in range(0, Data0_shape[0], chunk_size):\n",
    "        end_row = min(start_row + chunk_size, Data0_shape[0])\n",
    "\n",
    "        # Create query meshgrid corresponding to the Data0 shape for this chunk\n",
    "        Xq, Yq = np.meshgrid(np.arange(0, Data0_shape[1]),\n",
    "                             np.arange(start_row, end_row))\n",
    "        \n",
    "        # Convert Latitude and Longitude indices to integers\n",
    "        start_row_geo = int(start_row / 10)\n",
    "        end_row_geo = int(end_row / 10) + 1\n",
    "\n",
    "        # Flatten the X, Y for interpolation\n",
    "        points = np.column_stack([X[start_row_geo:end_row_geo, :].flatten(), Y[start_row_geo:end_row_geo, :].flatten()])\n",
    "\n",
    "        # Slice using Latitude and Longitude indices\n",
    "        lat_chunk = file['/Geometry_data/Latitude'][start_row_geo:end_row_geo, :].flatten()\n",
    "        lon_chunk = file['/Geometry_data/Longitude'][start_row_geo:end_row_geo, :].flatten()\n",
    "\n",
    "        # Interpolate Latitude and Longitude for the current chunk        \n",
    "        f_lat[start_row:end_row, :] = griddata(points, lat_chunk, (Xq, Yq), method='linear')\n",
    "        f_lon[start_row:end_row, :] = griddata(points, lon_chunk, (Xq, Yq), method='linear')\n",
    "\n",
    "    LLroi = {'Lat': f_lat, 'Lon': f_lon}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff302d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Plotting\n",
    "    fig = plt.figure()\n",
    "    plt.subplots_adjust(wspace=0.6, hspace=0.6)\n",
    "\n",
    "    ax1 = fig.add_subplot(1, 2, 1)\n",
    "    ax1.set_title(\"Latitude\")\n",
    "    im1 = ax1.imshow(LLroi['Lat'], vmin=30, vmax=45, cmap='jet')\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    divider = make_axes_locatable(ax1)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(im1, cax=cax)\n",
    "\n",
    "    ax2 = fig.add_subplot(1, 2, 2)\n",
    "    ax2.set_title(\"Longitude\")\n",
    "    im2 = ax2.imshow(LLroi['Lon'], vmin=125, vmax=145, cmap='jet')\n",
    "    plt.gca().set_aspect('equal', adjustable='box')\n",
    "    divider = make_axes_locatable(ax2)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "    plt.colorbar(im2, cax=cax)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a07d84",
   "metadata": {},
   "source": [
    "### Cut out target area\n",
    "This time, the area of the Kanto coast is targeted and cut out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8b5075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define latitude and longitude limits\n",
    "lat_min = 34.5\n",
    "lat_max = 36.5\n",
    "lon_min = 138\n",
    "lon_max = 141\n",
    "\n",
    "# Identify target area within specified latitude and longitude range\n",
    "tgt_area = (LLroi['Lat'] > lat_min) & (LLroi['Lat'] < lat_max) & (LLroi['Lon'] > lon_min) & (LLroi['Lon'] < lon_max)\n",
    "\n",
    "# Find the row indices where any value in the row satisfies the condition\n",
    "tgt_pix = np.where(np.sum(tgt_area, axis=1) > 0)[0]\n",
    "\n",
    "# Find the column indices where any value in the column satisfies the condition\n",
    "tgt_lin = np.where(np.sum(tgt_area, axis=0) > 0)[0]\n",
    "\n",
    "# Get the min and max indices for rows and columns\n",
    "pix_min = tgt_pix[0]\n",
    "pix_max = tgt_pix[-1]\n",
    "lin_min = tgt_lin[0]\n",
    "lin_max = tgt_lin[-1]\n",
    "\n",
    "# Extract the sub-region of lat and lon within the target area\n",
    "tgt_lat = LLroi['Lat'][pix_min:pix_max+1, lin_min:lin_max+1]\n",
    "tgt_lon = LLroi['Lon'][pix_min:pix_max+1, lin_min:lin_max+1]\n",
    "\n",
    "# Assuming data0 is a NumPy array, extract the corresponding data\n",
    "tgt_data0 = SGLI_Data1[pix_min:pix_max+1, lin_min:lin_max+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6f4b80",
   "metadata": {},
   "source": [
    "### Set resolution after map projection\n",
    "Create a grid after map projection. Here, try map projection at **0.01 [deg]** intervals.  \n",
    "0.01 deg is roughly 1 km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f140768",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddeg = 0.01\n",
    "\n",
    "# Create latitude and longitude grids with specified resolution ddeg\n",
    "latg = np.arange(lat_max, lat_min - ddeg, -ddeg)\n",
    "long = np.arange(lon_min, lon_max + ddeg, ddeg)\n",
    "\n",
    "# Generate a grid for map projection\n",
    "llg_lat, llg_lon = np.meshgrid(latg, long, indexing='ij')\n",
    "\n",
    "# Interpolation using griddata\n",
    "points = np.column_stack((tgt_lat.flatten(), tgt_lon.flatten()))\n",
    "values = tgt_data0.flatten()\n",
    "\n",
    "# Interpolate data over the new grid\n",
    "SGLI_Data2 = griddata(points, values, (llg_lat, llg_lon), method='linear')\n",
    "# Plotting\n",
    "fig = plt.figure()\n",
    "plt.subplots_adjust(wspace=0.6, hspace=0.6)\n",
    "\n",
    "# First subplot: original data\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.set_title(\"Scene Data\")\n",
    "ax1.set_xlabel('pixel')\n",
    "ax1.set_ylabel('line')\n",
    "im1 = ax1.imshow(tgt_data0, vmin=0, vmax=8, cmap='jet')\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "plt.colorbar(im1, cax=cax,label='CHLA [g/m^3]')\n",
    "\n",
    "# Second subplot: interpolated data in map projection\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.set_title(\"Map Projection\")\n",
    "ax2.set_xlabel('Longitude [deg]')\n",
    "ax2.set_ylabel('Latitude [deg]')\n",
    "im2 = ax2.pcolormesh(long, latg, SGLI_Data2, vmin=0, vmax=8, cmap='jet')\n",
    "ax2.set_aspect('equal', adjustable='box')\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "plt.colorbar(im2, cax=cax,label='CHLA [g/m^3]')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385d54a1",
   "metadata": {},
   "source": [
    "## MODIS FILE\n",
    "Then load the MODIS Chl-a data and map projection in the same way as for SGLI.\n",
    "### Check the structure of the netCDF file\n",
    "MODIS satellite data is distributed in netCDF format rather than hdf5 format.  \n",
    "The basic handling is the same, but there are a few points to note, which will be explained later.  \n",
    "First, let's look at the file structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3077c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODIS_FNAME = \"sample_images/AQUA_MODIS.20191013T035001.L2.OC.nc\"\n",
    "def PrintAllObjects(name):\n",
    "    print(name)\n",
    "\n",
    "with h5py.File(MODIS_FNAME,'r') as f:\n",
    "    f.visit(PrintAllObjects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e396a755",
   "metadata": {},
   "source": [
    "### Read dataset \n",
    "Files in netCDF format, such as MODIS, have slope and offset automatically applied when loaded in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496ba7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DNAME = '/geophysical_data/chlor_a'\n",
    "with h5py.File(MODIS_FNAME, 'r') as file:\n",
    "    # Read dataset\n",
    "    MODIS_Data0 = file[DNAME][:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680ac4c9",
   "metadata": {},
   "source": [
    "### check attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105084d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(MODIS_FNAME,'r') as file:\n",
    "    qa_flag_data_description = file['/geophysical_data/l2_flags'].attrs['flag_meanings']\n",
    "    qa_string = qa_flag_data_description.astype(str)\n",
    "    qa_string = qa_string.replace(' ', '\\n')\n",
    "    print(qa_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12792b13",
   "metadata": {},
   "source": [
    "### Applying the QA_flag\n",
    "As can be seen from the attribute, there are 32 QA_FLAGs in MODIS.   \n",
    "The QA flags of MODIS are stored in DN (-2147483648:2147483648) and the flag corresponding to the value of each bit when viewed as a binary number (type int32) is set.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d5271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(MODIS_FNAME, 'r') as file:\n",
    "    \n",
    "    # Read QA_flag\n",
    "    QA_flag = file['/geophysical_data/l2_flags'][:]\n",
    "    bit00 = np.bitwise_and(QA_flag, 2**1, dtype=np.int32)\n",
    "    bit01 = np.bitwise_and(QA_flag, 2**2, dtype=np.int32)\n",
    "    bit02 = np.bitwise_and(QA_flag, 2**3, dtype=np.int32)\n",
    "    bit03 = np.bitwise_and(QA_flag, 2**4, dtype=np.int32)\n",
    "    bit04 = np.bitwise_and(QA_flag, 2**5, dtype=np.int32)\n",
    "    bit05 = np.bitwise_and(QA_flag, 2**6, dtype=np.int32)\n",
    "    bit06 = np.bitwise_and(QA_flag, 2**7, dtype=np.int32)\n",
    "    bit07 = np.bitwise_and(QA_flag, 2**8, dtype=np.int32)\n",
    "    bit08 = np.bitwise_and(QA_flag, 2**9, dtype=np.int32)\n",
    "    bit09 = np.bitwise_and(QA_flag, 2**10, dtype=np.int32)\n",
    "    bit10 = np.bitwise_and(QA_flag, 2**11, dtype=np.int32)\n",
    "    bit11 = np.bitwise_and(QA_flag, 2**12, dtype=np.int32)\n",
    "    bit12 = np.bitwise_and(QA_flag, 2**13, dtype=np.int32)\n",
    "    bit13 = np.bitwise_and(QA_flag, 2**14, dtype=np.int32)\n",
    "    bit14 = np.bitwise_and(QA_flag, 2**15, dtype=np.int32)\n",
    "    bit15 = np.bitwise_and(QA_flag, 2**16, dtype=np.int32)\n",
    "    bit16 = np.bitwise_and(QA_flag, 2**17, dtype=np.int32)\n",
    "    bit17 = np.bitwise_and(QA_flag, 2**18, dtype=np.int32)\n",
    "    bit18 = np.bitwise_and(QA_flag, 2**19, dtype=np.int32)\n",
    "    bit19 = np.bitwise_and(QA_flag, 2**20, dtype=np.int32)\n",
    "    bit20 = np.bitwise_and(QA_flag, 2**21, dtype=np.int32)\n",
    "    bit21 = np.bitwise_and(QA_flag, 2**22, dtype=np.int32)\n",
    "    bit22 = np.bitwise_and(QA_flag, 2**23, dtype=np.int32)\n",
    "    bit23 = np.bitwise_and(QA_flag, 2**24, dtype=np.int32)\n",
    "    bit24 = np.bitwise_and(QA_flag, 2**25, dtype=np.int32)\n",
    "    bit25 = np.bitwise_and(QA_flag, 2**26, dtype=np.int32)\n",
    "    bit26 = np.bitwise_and(QA_flag, 2**27, dtype=np.int32)\n",
    "    bit27 = np.bitwise_and(QA_flag, 2**28, dtype=np.int32)\n",
    "    bit28 = np.bitwise_and(QA_flag, 2**29, dtype=np.int32)\n",
    "    bit29 = np.bitwise_and(QA_flag, 2**30, dtype=np.int32)\n",
    "    bit30 = np.bitwise_and(QA_flag, 2**31, dtype=np.int32)\n",
    "    bit31 = np.bitwise_and(QA_flag, 2**32, dtype=np.int32)\n",
    "    \n",
    "    #unreliable = np.logical_or.reduce([bit00,bit01,bit02,bit03,bit06,bit08,bit09,bit10])\n",
    "    unreliable = np.logical_or.reduce([bit00,bit01])\n",
    "    # Apply reliability mask\n",
    "    MODIS_Data0[unreliable] = np.nan\n",
    "    MODIS_Data0[MODIS_Data0<0] = np.nan\n",
    "\n",
    "    # Plotting with reliability mask\n",
    "    fig, ax = plt.subplots()\n",
    "    plt.imshow(MODIS_Data0, cmap='jet', vmin=0, vmax=5)\n",
    "    ax.set_title(\"SST with QA flags applied\")\n",
    "    plt.colorbar(label='CHLA [g/m^3]')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbd78c6",
   "metadata": {},
   "source": [
    "### Cut out target area\n",
    "Cut out the same area as the SGLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bedc02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define latitude and longitude limits\n",
    "lat_min = 34.5\n",
    "lat_max = 36.5\n",
    "lon_min = 138\n",
    "lon_max = 141\n",
    "\n",
    "with h5py.File(MODIS_FNAME, 'r') as file:\n",
    "    MODIS_lat = file[\"/navigation_data/latitude\"][:]\n",
    "    MODIS_lon = file[\"/navigation_data/longitude\"][:]\n",
    "    tgt_area = (MODIS_lat > lat_min) & (MODIS_lat < lat_max) & (MODIS_lon > lon_min) & (MODIS_lon < lon_max)\n",
    "    # Find the row indices where any value in the row satisfies the condition\n",
    "    tgt_pix = np.where(np.sum(tgt_area, axis=1) > 0)[0]\n",
    "    # Find the column indices where any value in the column satisfies the condition\n",
    "    tgt_lin = np.where(np.sum(tgt_area, axis=0) > 0)[0]\n",
    "\n",
    "    # Get the min and max indices for rows and columns\n",
    "    pix_min = tgt_pix[0]\n",
    "    pix_max = tgt_pix[-1]\n",
    "    lin_min = tgt_lin[0]\n",
    "    lin_max = tgt_lin[-1]\n",
    "\n",
    "    # Extract the sub-region of lat and lon within the target area\n",
    "    tgt_lat = MODIS_lat[pix_min:pix_max+1, lin_min:lin_max+1]\n",
    "    tgt_lon = MODIS_lon[pix_min:pix_max+1, lin_min:lin_max+1]\n",
    "\n",
    "    # Assuming data0 is a NumPy array, extract the corresponding data\n",
    "    tgt_data0 = MODIS_Data0[pix_min:pix_max+1, lin_min:lin_max+1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1924cb4c",
   "metadata": {},
   "source": [
    "### Set resolution after map projection\n",
    "Map projection with the same resolution(**0.01 [deg]**) as SGLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b902bfa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddeg = 0.01\n",
    "\n",
    "# Create latitude and longitude grids with specified resolution ddeg\n",
    "latg = np.arange(lat_max, lat_min - ddeg, -ddeg)\n",
    "long = np.arange(lon_min, lon_max + ddeg, ddeg)\n",
    "\n",
    "# Generate a grid for map projection\n",
    "llg_lat, llg_lon = np.meshgrid(latg, long, indexing='ij')\n",
    "\n",
    "# Interpolation using griddata\n",
    "points = np.column_stack((tgt_lat.flatten(), tgt_lon.flatten()))\n",
    "values = tgt_data0.flatten()\n",
    "\n",
    "# Interpolate data over the new grid\n",
    "MODIS_Data2 = griddata(points, values, (llg_lat, llg_lon), method='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c4e7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig = plt.figure()\n",
    "plt.subplots_adjust(wspace=0.6, hspace=0.6)\n",
    "\n",
    "# First subplot: original data\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.set_title(\"Scene Data\")\n",
    "ax1.set_xlabel('pixel')\n",
    "ax1.set_ylabel('line')\n",
    "im1 = ax1.imshow(tgt_data0, vmin=0, vmax=8, cmap='jet')\n",
    "ax1.set_aspect('equal', adjustable='box')\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "plt.colorbar(im1, cax=cax)\n",
    "\n",
    "# Second subplot: interpolated data in map projection\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.set_title(\"Map Projection\")\n",
    "ax2.set_xlabel('Longitude [deg]')\n",
    "ax2.set_ylabel('Latitude [deg]')\n",
    "im2 = ax2.pcolormesh(long, latg, MODIS_Data2, vmin=0, vmax=8, cmap='jet')\n",
    "ax2.set_aspect('equal', adjustable='box')\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax = divider.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "plt.colorbar(im2, cax=cax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ca22d",
   "metadata": {},
   "source": [
    "## Difference between SGLI and MODIS Chl-a estimates\n",
    "Let's now illustrate the deviation of Chl-a for SGLI and MODIS with the same extent and resolution of the map projection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0707299",
   "metadata": {},
   "outputs": [],
   "source": [
    "difference = SGLI_Data2 - MODIS_Data2\n",
    "\n",
    "# Second subplot: interpolated data in map projection\n",
    "fig, ax = plt.subplots()\n",
    "plt.set_cmap('bwr')\n",
    "#plt.imshow(difference, cmap='jet', vmin=0, vmax=5)\n",
    "plt.pcolor(long, latg, difference, vmin=-2, vmax=2)\n",
    "ax.set_title(\"Difference between SGLI and MODIS Chl-a estimates\")\n",
    "ax.set_xlabel('Longitude [deg]')\n",
    "ax.set_ylabel('Latitude [deg]')\n",
    "plt.colorbar(label='CHLA [g/m^3]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be265d50",
   "metadata": {},
   "source": [
    "## Histogram and scatter plots\n",
    "As the resolution is the same, it can also be used to create histograms and scatter plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a75c851",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "valid_mask = ~np.isnan(SGLI_Data2) & ~np.isnan(MODIS_Data2)  # Masking of data not containing NaN\n",
    "\n",
    "SGLI_valid = SGLI_Data2[valid_mask]\n",
    "MODIS_valid = MODIS_Data2[valid_mask]\n",
    "\n",
    "# Plotting\n",
    "fig = plt.figure(figsize=(10, 10)) \n",
    "plt.subplots_adjust(wspace=0.8, hspace=0.4) \n",
    "\n",
    "# First subplot: original data (histogram)\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax1.hist(SGLI_valid.flatten(), bins=30, label='SGLI', log=True, histtype=\"step\") \n",
    "ax1.hist(MODIS_valid.flatten(), bins=30, label='MODIS', log=True, histtype=\"step\")\n",
    "ax1.set_title(\"Histogram\")\n",
    "ax1.set_xlabel('CHLA [g/m^3]')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.set_aspect(1.0 / ax1.get_data_ratio())\n",
    "\n",
    "# Second subplot: scatter plot with regression line\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "ax2.scatter(SGLI_valid, MODIS_valid, s=1, label='Data Points')\n",
    "\n",
    "# Perform linear regression on valid data only\n",
    "slope, intercept = np.polyfit(SGLI_valid.flatten(), MODIS_valid.flatten(), 1)\n",
    "reg_line = slope * SGLI_valid + intercept\n",
    "\n",
    "# Plot the regression line\n",
    "if intercept >= 0:\n",
    "    ax2.plot(SGLI_valid, reg_line, color='red', label=f'y={slope:.2f}x+{intercept:.2f}')\n",
    "else:\n",
    "    ax2.plot(SGLI_valid, reg_line, color='red', label=f'y={slope:.2f}x{intercept:.2f}')\n",
    "\n",
    "\n",
    "ax2.set_title(\"Scatter plot with regression line\")\n",
    "ax2.set_xlabel('SGLI CHLA [g/m^3]')\n",
    "ax2.set_ylabel('MODIS CHLA [g/m^3]')\n",
    "ax2.legend()\n",
    "\n",
    "# Make the plot square\n",
    "ax2.set_aspect(1.0 / ax2.get_data_ratio())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f060664",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "324.023px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
